{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W LangChain do definiowania promptów są template strings.\n",
    "Treści zamknięte w klamrach {} są zastępowane przez LangChain konkretnymi wartościami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don't know\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "The Vercel AI SDK is an open-source library designed to help developers build conversational, streaming, and chat user interfaces in JavaScript and TypeScript. The SDK supports React/Next.js, Svelte/SvelteKit, with support for Nuxt/Vue coming soon.\n",
    "To install the SDK, enter the following command in your terminal:\n",
    "npm install ai\n",
    "\"\"\"\n",
    "system_template = \"\"\"\n",
    "As a {role} who answers the questions ultra-concisely using CONTEXT below \n",
    "and nothing more and truthfully says \"don't know\" when the CONTEXT is not enough to give an answer.\n",
    "\n",
    "context###{context}###\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{text}\"\n",
    "\n",
    "# Lista wiadomości\n",
    "messages = [\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "]\n",
    "\n",
    "# Inicjalizacja promptu\n",
    "chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Faktyczne uzupełnienie szablonów wartościami\n",
    "formatted_chat_prompt = chat_prompt.format_messages(\n",
    "    context= context,\n",
    "    role= \"Doświadczony programista JavaScript\",\n",
    "    text= \"Co to wyrażenia lambda w Pythonie?\",\n",
    ")\n",
    "\n",
    "# Inicjalizacja domyślnego modelu, czyli gpt-3.5-turbo\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "# Wykonanie zapytania do modelu\n",
    "response =  chat.invoke(formatted_chat_prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W Pythonie można do tego wykorzystać po prostu fstringi (przy okazji test prompta w wersji polskiej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie wiem.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "context = \"\"\"\n",
    "Vercel AI SDK to biblioteka typu open-source zaprojektowana, aby pomóc programistom tworzyć interfejsy użytkownika dla konwersacji, streamingu i czatu w JavaScript i TypeScript. SDK wspiera React/Next.js, Svelte/SvelteKit, przy czym wsparcie dla Nuxt/Vue będzie dostępne wkrótce.\n",
    "Aby zainstalować SDK, wprowadź następujące polecenie w terminalu:\n",
    "npm install ai\n",
    "\"\"\"\n",
    "role= \"Doświadczony programista JavaScript\",\n",
    "system_template = f\"\"\"\n",
    "Jako {role}, która odpowiada na pytania bardzo precyzyjnie, używając KONTEKSTU poniżej \n",
    "i nic więcej, i zgodnie z prawdą mówi \"nie wiem\", gdy KONTEKST nie wystarcza do udzielenia odpowiedzi.\n",
    "\n",
    "kontekst##{context}##\n",
    "\"\"\"\n",
    "text= \"Co to wyrażenia lambda w Pythonie?\",\n",
    "human_template = f\"{text}\"\n",
    "\n",
    "# Inicjalizacja domyślnego modelu, czyli gpt-3.5-turbo\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "# Wykonanie zapytania do modelu\n",
    "response =  chat.invoke([\n",
    "    SystemMessage(system_template),\n",
    "    HumanMessage(human_template),\n",
    "])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
