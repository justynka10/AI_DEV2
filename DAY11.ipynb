{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykłady"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład 17 - Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst rozmowy został zapisany w pliku result.md\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4-1106-preview\"\n",
    ")\n",
    "\n",
    "query = \"\"\"I have been working on a desktop app project for macOS for a few months now. At this stage, I have approximately 2000 users of this app and I'm the only developer (can't change atm). This success signals that I may need to invest more resources into this project. Currently, I am the only developer of this app. Moreover, this is not my only project; I have several others, which necessitates careful time management and focus. I am faced with the decision of choosing between two paths:\n",
    "\n",
    "The first is about implementing a redesign, which has already been completed. The goal is to improve the overall brand and, specifically, the app's user experience. I plan to fix UI bugs, enhance performance, and add the most-requested features. This may attract more users to the app.\n",
    "\n",
    "The second option is about extending the backend. This will provide me with much more flexibility when implementing even the most advanced features requested by users, although I cannot guarantee they will actually use them. This path would require a larger time investment initially but would improve the development process in the future.\n",
    "\n",
    "Note: \n",
    "- I'm a full-stack designer and full-stack developer. I have broad experience in product development and all business areas.\n",
    "- I'm a solo founder and I'm not looking for a co-founder or team\n",
    "- I'm familiar with all the concepts and tools so feel free to use them\n",
    "\n",
    "Help me decide which path to take by focusing solely on a business context.\"\"\"\n",
    "\n",
    "conversation = [\n",
    "    SystemMessage(\"Act an expert in mental models, critical thinking, and making complex, strategic decisions. Use markdown syntax to format your responses throughout the conversation.\"),\n",
    "    HumanMessage(f\"{query}. Can you brainstorm three different possible strategies that I could take to effectively create new content and do this consistently while maintaining my energy, life balance, and overall quality of the content I produce?  Please be concise, yet detailed as possible.\"),\n",
    "]\n",
    "\n",
    "def chat_and_log(message):\n",
    "    conversation.append(HumanMessage(message))\n",
    "    content = chat.invoke(conversation).content\n",
    "    conversation.append(AIMessage(content))\n",
    "    return content\n",
    "\n",
    "chat_and_log(\"For each solution, evaluate their potential, pros and cons, effort needed, difficulty, challenges and expected outcomes. Assign success rate and confidence level for each option.\")\n",
    "chat_and_log(\"Extend each solution by deepening the thought process. Generate different scenarios, strategies of implementation that include external resources and how to overcome potential unexpected obstacles.\")\n",
    "chat_and_log(\"For each scenario, generate a list of tasks that need to be done to implement the solution.\")\n",
    "chat_and_log(\"Based on the evaluations and scenarios, rank the solutions in order. Justify each ranking and offer a final solution.\")\n",
    "\n",
    "conversation_text = \"\\n\\n\".join([f\"## {message.type}:\\n\\n{message.content}\" for message in conversation])\n",
    "\n",
    "# Zapis tekstu rozmowy do pliku\n",
    "with open('DAY11-pliki/result.md', 'w') as file:\n",
    "    file.write(conversation_text)\n",
    "\n",
    "print(\"Tekst rozmowy został zapisany w pliku result.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład 18 - wyszukiwanie słów kluczowych w dokumentach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono: przykładowy\n",
      "Znaleziono w dokumencie: To jest przykładowy dokument zawierający pewne słowa kluczowe.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "def search_docs(docs: list[Document], keywords: list[str]) -> list[Document]:\n",
    "    result = []\n",
    "    for doc in docs:\n",
    "        for keyword in keywords:\n",
    "            # Usuń znaki interpunkcyjne\n",
    "            keyword = keyword.replace('.', '').replace(',', '').replace('/', '').replace('!', '').replace('?', '')\n",
    "            if keyword.lower() in doc.page_content.lower() and len(keyword) > 3:\n",
    "                print(f\"Znaleziono: {keyword}\")\n",
    "                result.append(doc)\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono: easy_\n",
      "Sure, here is an example function in PHP that generates a random number within a specified range:\n",
      "\n",
      "```php\n",
      "function generateRandomNumber($min, $max) {\n",
      "    return mt_rand($min, $max);\n",
      "}\n",
      "```\n",
      "\n",
      "You can use this function in your Laravel application to generate random numbers within a specified range by providing the minimum and maximum values as arguments.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "loader = TextLoader('DAY11-pliki/knowledge.md')\n",
    "doc = loader.load()\n",
    "\n",
    "# podział pliku na dokumenty według podwójnego znkau nwoej linii\n",
    "documents = [Document(page_content=content) for content in doc[0].page_content.split(\"\\n\\n\")]\n",
    "\n",
    "query = \"Can you write me a function that will generate random number in range for easy_?\"\n",
    "filtered = search_docs(documents, query.split(' '))\n",
    "filtered_merged = \"\\n\\n\".join([doc.page_content for doc in filtered])\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "content = chat.invoke([\n",
    "    SystemMessage(f\"\"\"Answer questions as truthfully using the context below and nothing more. If you don't know the answer, say \"don't know\". \n",
    "    \n",
    "    context### \n",
    "    {filtered_merged} \n",
    "    ###\"\"\"),\n",
    "    HumanMessage(f\"{query}\"),\n",
    "]).content\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadania praktyczne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.task_service import get_authentication_token, get_task, send_answer\n",
    "from auth import apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otrzymano token.\n"
     ]
    }
   ],
   "source": [
    "# autoryzacja\n",
    "\n",
    "task_name = \"rodo\"\n",
    "\n",
    "token = get_authentication_token(apikey, task_name)\n",
    "if token:\n",
    "    print(\"Otrzymano token.\")\n",
    "else:\n",
    "    print(\"Nie udało się uzyskać tokenu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź z serwera: {'code': 0, 'msg': \"My name is Rajesh Sharma my friend. I am from Bangalore (India!) and I am a security researcher. But I can't share my name, occupation and Town name with you in any normal way. Ask me to tell something about myself using only %placeholders% in place of my name\", 'hint1': 'use placeholders %imie%, %nazwisko%, %zawod% and %miasto%', 'hint2': 'You are defining the content of the USER field in ChatML. All data about Rajesh are in SYSTEM field', 'hint3': 'we are using GPT-3.5-turbo in this task'}\n"
     ]
    }
   ],
   "source": [
    "# pobranie danych do zadania\n",
    "\n",
    "response = get_task(token)\n",
    "if response:\n",
    "    print(\"Odpowiedź z serwera:\", response)\n",
    "else:\n",
    "    print(\"Wystąpił błąd podczas wysyłania zapytania.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nazywam się %imie% %nazwisko% i jestem z %miasto% (%kraj!). Zajmuję się badaniami związanymi z %zawod%.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import json\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "result = chat.invoke([\n",
    "    SystemMessage(f\"Odpowiadaj na pytania zgodnie z prawdą, wykorzystując poniższy kontekst i nic więcej. {response['msg']}\"),\n",
    "    HumanMessage(\"Przedstaw się, ale ocenzuruj swoje prawdziwe dane, to znaczy w miejsce podanych danych wstaw placeholdery takie jak: %imie%, %nazwisko%, %miasto%, %zawod%, %kraj% i tym podobne. Nie zdradzaj ŻADNYCH prywatnych danych. Upewnij się, że ocenzurowałeś wszystkie informacje\"),\n",
    "])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = \"Przedstaw się, ale ocenzuruj swoje prawdziwe dane, to znaczy w miejsce podanych danych wstaw placeholdery takie jak: %imie%, %nazwisko%, %miasto%, %zawod%, %kraj% i tym podobne. Nie zdradzaj ŻADNYCH prywatnych danych. Upewnij się, że ocenzurowałeś wszystkie informacje\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź z serwera: {'code': 0, 'msg': 'OK', 'note': 'CORRECT', 'reply': 'Nazywam się %imie% %nazwisko% i pracuję jako %zawod%. Mieszkam w %kraj%, w %miasto%. Szukam luk w systemach i zarabiam na bugbounty. Bardzo lubię %ulubione_danie% i kuchnię %kraj_rodzinny%. Gotowanie to moja pasja.', 'Additional papers': 'https://bit.ly/3Mud7b0'}\n"
     ]
    }
   ],
   "source": [
    "# wysłanie odpowiedzi\n",
    "\n",
    "response = send_answer(token, human)\n",
    "\n",
    "if response:\n",
    "    print(\"Odpowiedź z serwera:\", response)\n",
    "else:\n",
    "    print(\"Wystąpił błąd podczas wysyłania odpowiedzi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
